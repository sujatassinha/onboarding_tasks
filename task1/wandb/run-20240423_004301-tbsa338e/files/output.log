Average sequence length: 91.34038650085759
Min, Median, Max sequence length: [1, 72, 1151]
Number of indices to drop for input length: 132635
Average sequence length: 99.35036414859839
Min, Median, Max sequence length: [4, 84, 1151]
Number of indices to drop for output length: 118172
Initial Dataset is of shape: (2095985, 4)
Final   Dataset is of shape: (1940163, 4)
Shapes for, Train Dataset: (1552130, 4), Test Dataset: (388033, 4)
['input_ids', 'attention_mask', 'labels']
['input_ids', 'attention_mask', 'labels']
trainable params: 4065280 || all params: 156189952 || trainable%: 2.6027794668891375
Initiating Fine-Tuning for the model on our dataset
Epoch: 0
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Loss:  11.622883796691895
Loss:  1.1370434761047363
Loss:  0.8418352007865906
Loss:  0.7379652857780457
Loss:  0.6570279598236084
Loss:  0.5514339208602905
Loss:  0.5649956464767456
Loss:  0.5749770402908325
Loss:  0.4888269603252411
Loss:  0.5027675032615662
Loss:  0.4849564731121063
Loss:  0.5178415775299072
Loss:  0.4924772381782532
Loss:  0.512355625629425
Time : 1704.84761095047 secs
Now generating paraphrases on our fine tuned model for the validation dataset and saving it in a dataframe
Completed 0