{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJbDH1n4c_w8"
      },
      "source": [
        "#### Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFn8EWJ7c5oj",
        "outputId": "0299e36f-b96a-47d6-dcc8-f4bc221a2056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets wandb evaluate accelerate -qU\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHIs_xJNdCeC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /to_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEAMayoRdXQw"
      },
      "source": [
        "#### Logging into Weights and Biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9sygIGHdaAS"
      },
      "outputs": [],
      "source": [
        "# Setup enviroment variables to enable logging to Weights & Biases\n",
        "import os\n",
        "# can be \"end\", \"checkpoint\" or \"false\"\n",
        "os.environ['WANDB_LOG_MODEL'] = \"checkpoint\"\n",
        "# the name of the wandb project defaults to `huggingface`\n",
        "os.environ['WANDB_PROJECT'] = \"hf_transformers\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp41IQwAdafL"
      },
      "outputs": [],
      "source": [
        "# Login and authenticate Weights & Biases\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssTdzrCsdc5k"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/docs/transformers/model_doc/t5#t5tokenizer\n",
        "access_token = 'token_string'\n",
        "wandb_project = \"t5-finetune-paraphrases-trainer\"\n",
        "dataset_name = \"humarin/chatgpt-paraphrases\"\n",
        "model_id = \"google-t5/t5-base\"\n",
        "base_model_name = \"google\"\n",
        "run_name = base_model_name + \"-\" + wandb_project\n",
        "save_directory = \"./outputs/\" + run_name\n",
        "gradient_accumulation_steps = 1\n",
        "max_input_length = 64\n",
        "max_output_length = 64#100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS25jeQlhU63"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# WandB – Initialize a new run\n",
        "wandb.init(project=wandb_project)\n",
        "\n",
        "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
        "# Defining some key variables that will be used later on in the training\n",
        "config = wandb.config          # Initialize config\n",
        "config.TRAIN_BATCH_SIZE = 64#100    # input batch size for training (default: 64)\n",
        "config.VALID_BATCH_SIZE = 64#100    # input batch size for testing (default: 1000)\n",
        "config.TRAIN_EPOCHS = 15#50        # number of epochs to train (default: 10)\n",
        "config.VAL_EPOCHS = 1\n",
        "config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
        "config.SEED = 42               # random seed (default: 42)\n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "torch.manual_seed(config.SEED) # pytorch random seed\n",
        "np.random.seed(config.SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tesJbpHhX1y"
      },
      "outputs": [],
      "source": [
        "if len(wandb_project) > 0:\n",
        "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7oM7l8zi3Ah"
      },
      "source": [
        "#### Accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk_tVOvWhce-"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator, DataLoaderConfiguration\n",
        "\n",
        "dataloader_config = DataLoaderConfiguration(\n",
        "    dispatch_batches=None,\n",
        "    split_batches=False,\n",
        "    even_batches=True,\n",
        "    use_seedable_sampler=True\n",
        ")\n",
        "\n",
        "accelerator = Accelerator(dataloader_config=dataloader_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odM0TlLejAKc"
      },
      "source": [
        "#### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv4DKIQYi4zH"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(dataset_name, token=access_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-VdxklmjDS7"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "# Convert string representation of list to actual list\n",
        "def convert_paraphrases_to_list(example):\n",
        "    example['paraphrases'] = ast.literal_eval(example['paraphrases'])\n",
        "    return example\n",
        "\n",
        "dataset = dataset[\"train\"].map(convert_paraphrases_to_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pnwbanajFPD"
      },
      "outputs": [],
      "source": [
        "# Expand each row for each paraphrase\n",
        "def expand_dataset(examples):\n",
        "    new_examples = {'text': [], 'paraphrase': [], 'category': [], 'source': []}\n",
        "    for text, paraphrases, category, source in zip(examples['text'], examples['paraphrases'], examples['category'], examples['source']):\n",
        "        for paraphrase in paraphrases:\n",
        "            new_examples['text'].append(text)\n",
        "            new_examples['paraphrase'].append(paraphrase)\n",
        "            new_examples['category'].append(category)\n",
        "            new_examples['source'].append(source)\n",
        "    return new_examples\n",
        "\n",
        "# Expand the dataset\n",
        "dataset = dataset.map(expand_dataset, batched=True, remove_columns=['paraphrases'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-L47Hr14KuV"
      },
      "source": [
        "#### Adjust input/output sequence lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dCYsc6d4OVJ"
      },
      "outputs": [],
      "source": [
        "# Find the maximum input and output sequence length\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "\n",
        "def plot_sequence_lengths(dataset_obj, seq_length=150, input_text=True, to_plot=True):\n",
        "\n",
        "  # Initialize a list to store sequence lengths\n",
        "  sequence_lengths = []\n",
        "\n",
        "  # list of indices that are too long\n",
        "  too_long = []\n",
        "\n",
        "  # Loop over the dataset and get the length of text sequences\n",
        "  for idx, example in enumerate(dataset_obj):\n",
        "    if input_text:\n",
        "      sequence_lengths.append(len(example['text']))\n",
        "    else:\n",
        "      sequence_lengths.append(len(example['paraphrase']))\n",
        "    if sequence_lengths[idx] >= seq_length:\n",
        "      too_long.append(idx)\n",
        "\n",
        "  # Plot histogram\n",
        "  if to_plot:\n",
        "    plt.figure(figsize=(4,2))\n",
        "    plt.grid()\n",
        "    plt.hist(sequence_lengths, bins=30)\n",
        "    plt.xlabel('Sequence Length')\n",
        "    plt.ylabel('Text Sequence')\n",
        "    plt.title('Distribution of Text Sequence Lengths')\n",
        "    plt.show()\n",
        "\n",
        "  print(f\"Average sequence length: {sum(sequence_lengths)/len(sequence_lengths)}\")\n",
        "  print(f\"Min, Median, Max sequence length: [{min(sequence_lengths)}, {statistics.median(sequence_lengths)}, {max(sequence_lengths)}]\")\n",
        "\n",
        "  return too_long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKfgds-I4h4d",
        "outputId": "5589ef10-9b3d-457d-f669-381dd639bde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average sequence length: 91.34038650085759\n",
            "Min, Median, Max sequence length: [1, 72, 1151]\n",
            "Number of indices to drop for input length: 132635\n"
          ]
        }
      ],
      "source": [
        "indices_to_drop_input = plot_sequence_lengths(dataset, seq_length=200, input_text=True, to_plot=False)\n",
        "print(f\"Number of indices to drop for input length: {len(indices_to_drop_input)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3utj7z1e4pZ8",
        "outputId": "9cec0ed1-155b-4817-b8aa-3a7eaa524642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average sequence length: 99.35036414859839\n",
            "Min, Median, Max sequence length: [4, 84, 1151]\n",
            "Number of indices to drop for output length: 118172\n"
          ]
        }
      ],
      "source": [
        "indices_to_drop_output = plot_sequence_lengths(dataset, seq_length=200, input_text=False, to_plot=False)\n",
        "print(f\"Number of indices to drop for output length: {len(indices_to_drop_output)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "-2Yt-QGb4vtH",
        "outputId": "e39323ce-a6e8-4d59-cde1-e4aae23c766c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib_venn import venn2\n",
        "\n",
        "Ab = set(indices_to_drop_input)  - set(indices_to_drop_output)\n",
        "aB = set(indices_to_drop_output) - set(indices_to_drop_input)\n",
        "AB = set(indices_to_drop_input) & set(indices_to_drop_output)\n",
        "\n",
        "plt.figure(figsize=(4,2))\n",
        "venn2(subsets = (len(list(Ab)), len(list(aB)), len(list(AB))), set_labels = ('Group A', 'Group B'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goiquiwH4zG1",
        "outputId": "b45a7aa5-931e-4cb4-e599-3a7bfa6b90ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dataset is of shape: (2095985, 4)\n",
            "Final   Dataset is of shape: (1940163, 4)\n"
          ]
        }
      ],
      "source": [
        "# Drop indices in Ab, aB, and AB\n",
        "import itertools\n",
        "\n",
        "drop_indices = set(itertools.chain(list(Ab), list(aB), list(AB)))\n",
        "\n",
        "print(f\"Initial Dataset is of shape: {dataset.shape}\")\n",
        "\n",
        "# Convert generator to list to make it hashable\n",
        "selected_indices = [idx for idx in range(len(dataset)) if idx not in drop_indices]\n",
        "\n",
        "# Create a new dataset excluding those indices\n",
        "dataset = dataset.select(selected_indices)\n",
        "\n",
        "print(f\"Final   Dataset is of shape: {dataset.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zkBw8OJD6FGl",
        "outputId": "86222a59-82ef-4875-8688-4d04f05456bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# create new dataset exluding those idx\\ndataset = dataset.select(\\n    (\\n        idx for idx in range(len(dataset))\\n        if idx not in drop_indices\\n    )\\n)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "'''# create new dataset exluding those idx\n",
        "dataset = dataset.select(\n",
        "    (\n",
        "        idx for idx in range(len(dataset))\n",
        "        if idx not in drop_indices\n",
        "    )\n",
        ")'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EByJC5L6jT7P"
      },
      "source": [
        "#### Split dataset into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZkk9nMEjRC4",
        "outputId": "fe985400-5f0b-40c9-c8ff-ddd8269eba85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes for, Train Dataset: (1552130, 4), Test Dataset: (388033, 4)\n"
          ]
        }
      ],
      "source": [
        "train_test_ratio = 0.8\n",
        "split_dataset = dataset.train_test_split(test_size=1-train_test_ratio)\n",
        "\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]\n",
        "print(f\"Shapes for, Train Dataset: {train_dataset.shape}, Test Dataset: {test_dataset.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e8mVKhFjjBV"
      },
      "outputs": [],
      "source": [
        "# Adding 'paraphrase: ' text in front of the 'text'\n",
        "def modify_prompt(prompt):\n",
        "    prompt['text'] = 'paraphrase: ' + prompt['text']\n",
        "    return prompt\n",
        "\n",
        "def split_text(prompt):\n",
        "  prompt['text']=' '.join(prompt['text'].split())\n",
        "  prompt['paraphrase']=' '.join(prompt['paraphrase'].split())\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfDqd2wkjl9j"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(modify_prompt).map(split_text)\n",
        "test_dataset  = test_dataset.map(modify_prompt).map(split_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwTDbywazB-h"
      },
      "source": [
        "#### Obtain Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu-QDjdQypvN"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    token=access_token,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yyj6EH9zFUO"
      },
      "outputs": [],
      "source": [
        "# Tokenize 'text', save 'input_ids' as 'source_ids', and 'attention_mask' as 'source_mask'\n",
        "# Tokenize 'parphrase', save 'input_ids' as 'target_ids', and 'attention_mask' as 'target_mask'\n",
        "def tokenize_function(prompt):\n",
        "    # Tokenize the prompt['paraphrase']\n",
        "    result = tokenizer(prompt['paraphrase'],\n",
        "                       max_length=max_output_length,\n",
        "                       padding='max_length',\n",
        "                       truncation=True,  # Ensure longer texts are truncated to 'max_length'\n",
        "                       #return_tensors='pt'  # Return PyTorch tensors\n",
        "    )\n",
        "    # Copy the input_ids to use as labels\n",
        "    result['labels'] = result['input_ids'].copy() #.clone()\n",
        "    # Replace padding token id's in the labels with -100 so they are ignored by the loss\n",
        "    #padding_token_id = tokenizer.pad_token_id\n",
        "    #result['labels'][result['labels'] == padding_token_id] = -100\n",
        "\n",
        "    # Tokenize the prompt['text']\n",
        "    text_tokenized = tokenizer(prompt['text'],\n",
        "                               max_length=max_input_length,\n",
        "                               padding=\"max_length\",truncation=True,  # Ensure longer texts are truncated to 'max_length'\n",
        "                               #return_tensors='pt'  # Return PyTorch tensors\n",
        "    )\n",
        "    # Copy the input_ids and attention_mask to use as input text's id and mask\n",
        "    result['input_ids'] = text_tokenized['input_ids']\n",
        "    result['attention_mask'] = text_tokenized['attention_mask']\n",
        "    #result['source_ids'] = text_tokenized['input_ids']\n",
        "    #result['source_mask'] = text_tokenized['attention_mask']\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd4ZD6x80SUl"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset  = train_dataset.map(tokenize_function, batched=True).shuffle(seed=config.SEED) #num_rows: 1746146 for a 90|10 train|test split\n",
        "tokenized_test_dataset  = test_dataset.map(tokenize_function, batched=True).shuffle(seed=config.SEED)   #num_rows: 194017"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxEeVxX-81Nx"
      },
      "source": [
        "#### Post Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW2NWBQ984rx",
        "outputId": "b46023de-96e1-42c8-84b7-f0076850c258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['input_ids', 'attention_mask', 'labels']\n",
            "['input_ids', 'attention_mask', 'labels']\n"
          ]
        }
      ],
      "source": [
        "tokenized_train_dataset = tokenized_train_dataset.remove_columns(['text', 'category', 'source', 'paraphrase'])\n",
        "tokenized_test_dataset = tokenized_test_dataset.remove_columns(['text', 'category', 'source', 'paraphrase'])\n",
        "\n",
        "print(tokenized_train_dataset.column_names)\n",
        "print(tokenized_test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX8czVDEiorb"
      },
      "outputs": [],
      "source": [
        "# Set datatype format for the dataset objects\n",
        "tokenized_train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "tokenized_test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkSfIGcf9Gak"
      },
      "outputs": [],
      "source": [
        "#len(tokenized_train_dataset['input_ids'][0]), len(tokenized_train_dataset['attention_mask'][0]), len(tokenized_train_dataset['labels'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5RpzQ8aywlC"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset=tokenized_train_dataset.select(range(54000))\n",
        "tokenized_test_dataset=tokenized_test_dataset.select(range(6000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZpaRcCBAb-S"
      },
      "source": [
        "#### Create Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4G0NyUvAd_e"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(tokenized_train_dataset, shuffle=False, batch_size=config.TRAIN_BATCH_SIZE)\n",
        "test_dataloader = DataLoader(tokenized_test_dataset, shuffle=False, batch_size=config.VALID_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g8P7lm2Bz5W"
      },
      "source": [
        "#### Obtain Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sL9SxcYkB1uV"
      },
      "outputs": [],
      "source": [
        "# We are using t5-base model and added a Language model layer on top for generation of Paraphrases.\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "# BitsAndBytes configuration setup\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Defining the model. Further this model is sent to device (GPU/TPU) for using the hardware using accelerate.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    token=access_token\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl3uAJCGCE0D"
      },
      "source": [
        "#### Add adapters to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LYCnEA2CS2l"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N1sR_cnCHQU"
      },
      "outputs": [],
      "source": [
        "# Add adapters to model\n",
        "# wrap the entire protocol for preparing a model before running a training\n",
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model) #use_gradient_checkpointing (defaults to True) — If True, use gradient checkpointing to save memory at the expense of slower backward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c332BtsCOlB",
        "outputId": "84cdfd30-a97c-4ba7-87c5-ec5eef1bf659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 4065280 || all params: 156189952 || trainable%: 2.6027794668891375\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16, #64\n",
        "    lora_alpha=32, #16\n",
        "    target_modules=[\n",
        "        \"q\",\n",
        "        \"k\",\n",
        "        \"v\",\n",
        "        \"o\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.1,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    init_lora_weights=False,\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.config.use_cache = False\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5OnTivAzdzZ"
      },
      "source": [
        "#### Define Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiuEmcRLiKsV"
      },
      "outputs": [],
      "source": [
        "# Employ accelerator\n",
        "model, train_dataloader, test_dataloader = accelerator.prepare(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    test_dataloader,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts_PgwYQoyr-"
      },
      "outputs": [],
      "source": [
        "# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n",
        "# The model is put into train mode and then we wnumerate over the training loader and passed to the defined network\n",
        "\n",
        "def train(epoch, tokenizer, model, loader, optimizer):\n",
        "    model.train()\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "    for itr, batch in enumerate(loader, 0):\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        if itr%64 == 0:\n",
        "          wandb.log({\"Training Loss\": loss.item()})\n",
        "        if itr%64==0:\n",
        "            print(f'Loss:  {loss.item()}')\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjxZTOuzz9_Z"
      },
      "source": [
        "#### Define Validation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDe7d8Er0AX6"
      },
      "outputs": [],
      "source": [
        "def validate(epoch, tokenizer, model, loader):\n",
        "    model.eval()\n",
        "    input_texts = []\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for itr, batch in enumerate(loader, 0):\n",
        "            input_ids=batch['input_ids'].squeeze(0)\n",
        "            attention_mask=batch['attention_mask'].squeeze(0)\n",
        "            generated_ids = model.generate(\n",
        "                      input_ids=input_ids,\n",
        "                      attention_mask=attention_mask,\n",
        "                      max_length=max_output_length,\n",
        "                      num_beams=2,\n",
        "                      repetition_penalty=2.5,\n",
        "                      length_penalty=1.0,\n",
        "                      early_stopping=True\n",
        "                      )\n",
        "            input_text = [tokenizer.decode(it, skip_special_tokens=True, clean_up_tokenization_spaces=True) for it in batch['input_ids']]\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in batch['labels']]\n",
        "            if itr%64==0:\n",
        "              print(f'Completed {itr}')\n",
        "            input_texts.extend(input_text)\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return input_texts, predictions, actuals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o4qSt0XuYH1"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng57Mk-8uY4d",
        "outputId": "a497c5d1-f8a3-4057-f5ea-3ea31f3aef62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating Fine-Tuning for the model on our dataset\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  11.622883796691895\n",
            "Loss:  1.1370434761047363\n",
            "Loss:  0.8418352007865906\n",
            "Loss:  0.7379652857780457\n",
            "Loss:  0.6570279598236084\n",
            "Loss:  0.5514339208602905\n",
            "Loss:  0.5649956464767456\n",
            "Loss:  0.5749770402908325\n",
            "Loss:  0.4888269603252411\n",
            "Loss:  0.5027675032615662\n",
            "Loss:  0.4849564731121063\n",
            "Loss:  0.5178415775299072\n",
            "Loss:  0.4924772381782532\n",
            "Loss:  0.512355625629425\n",
            "Time : 1703.4873778820038 secs\n",
            "Epoch: 1\n",
            "Loss:  0.5719186663627625\n",
            "Loss:  0.523298978805542\n",
            "Loss:  0.46953222155570984\n",
            "Loss:  0.4754849672317505\n",
            "Loss:  0.4760311543941498\n",
            "Loss:  0.4485892951488495\n",
            "Loss:  0.45562902092933655\n",
            "Loss:  0.5007117390632629\n",
            "Loss:  0.38989266753196716\n",
            "Loss:  0.4390287697315216\n",
            "Loss:  0.43093058466911316\n",
            "Loss:  0.4676705598831177\n",
            "Loss:  0.45406031608581543\n",
            "Loss:  0.44518232345581055\n",
            "Time : 1706.736218214035 secs\n",
            "Epoch: 2\n",
            "Loss:  0.5174921751022339\n",
            "Loss:  0.48696160316467285\n",
            "Loss:  0.44033029675483704\n",
            "Loss:  0.443538099527359\n",
            "Loss:  0.4403114318847656\n",
            "Loss:  0.4190007448196411\n",
            "Loss:  0.4211224913597107\n",
            "Loss:  0.4695132374763489\n",
            "Loss:  0.3773844242095947\n",
            "Loss:  0.41120702028274536\n",
            "Loss:  0.41678351163864136\n",
            "Loss:  0.44238582253456116\n",
            "Loss:  0.42241939902305603\n",
            "Loss:  0.42751094698905945\n",
            "Time : 1705.4655458927155 secs\n",
            "Epoch: 3\n",
            "Loss:  0.49704766273498535\n",
            "Loss:  0.47256672382354736\n",
            "Loss:  0.4094015657901764\n",
            "Loss:  0.4262097179889679\n",
            "Loss:  0.4290701448917389\n",
            "Loss:  0.4010501205921173\n",
            "Loss:  0.4033149480819702\n",
            "Loss:  0.45538291335105896\n",
            "Loss:  0.36573225259780884\n",
            "Loss:  0.39935582876205444\n",
            "Loss:  0.40258824825286865\n",
            "Loss:  0.4311344623565674\n",
            "Loss:  0.41811859607696533\n",
            "Loss:  0.41148361563682556\n",
            "Time : 1706.6030066013336 secs\n",
            "Epoch: 4\n",
            "Loss:  0.48023608326911926\n",
            "Loss:  0.4500730335712433\n",
            "Loss:  0.3993150293827057\n",
            "Loss:  0.40840956568717957\n",
            "Loss:  0.4114709198474884\n",
            "Loss:  0.39124760031700134\n",
            "Loss:  0.3912838101387024\n",
            "Loss:  0.43116384744644165\n",
            "Loss:  0.35782769322395325\n",
            "Loss:  0.3915851414203644\n",
            "Loss:  0.38680675625801086\n",
            "Loss:  0.4227529466152191\n",
            "Loss:  0.4150603115558624\n",
            "Loss:  0.40744632482528687\n",
            "Time : 1703.1079995632172 secs\n",
            "Epoch: 5\n",
            "Loss:  0.46909821033477783\n",
            "Loss:  0.4498452842235565\n",
            "Loss:  0.39869484305381775\n",
            "Loss:  0.3968406021595001\n",
            "Loss:  0.40677082538604736\n",
            "Loss:  0.3747127950191498\n",
            "Loss:  0.3876233994960785\n",
            "Loss:  0.4233524203300476\n",
            "Loss:  0.34423431754112244\n",
            "Loss:  0.3812287151813507\n",
            "Loss:  0.3804011046886444\n",
            "Loss:  0.41015082597732544\n",
            "Loss:  0.39427584409713745\n",
            "Loss:  0.401571661233902\n",
            "Time : 1701.9897260665894 secs\n",
            "Epoch: 6\n",
            "Loss:  0.4674724042415619\n",
            "Loss:  0.43827375769615173\n",
            "Loss:  0.3739866614341736\n",
            "Loss:  0.40261879563331604\n",
            "Loss:  0.4066867530345917\n",
            "Loss:  0.3719484210014343\n",
            "Loss:  0.37476488947868347\n",
            "Loss:  0.4326135516166687\n",
            "Loss:  0.3350197672843933\n",
            "Loss:  0.377503901720047\n",
            "Loss:  0.3650287985801697\n",
            "Loss:  0.39845019578933716\n",
            "Loss:  0.3950526714324951\n",
            "Loss:  0.38216063380241394\n",
            "Time : 1703.8002045154572 secs\n",
            "Epoch: 7\n",
            "Loss:  0.4557657539844513\n",
            "Loss:  0.4301970303058624\n",
            "Loss:  0.38394030928611755\n",
            "Loss:  0.392040878534317\n",
            "Loss:  0.40153375267982483\n",
            "Loss:  0.36784330010414124\n",
            "Loss:  0.37674015760421753\n",
            "Loss:  0.41369757056236267\n",
            "Loss:  0.33462509512901306\n",
            "Loss:  0.36078885197639465\n",
            "Loss:  0.36027753353118896\n",
            "Loss:  0.3924787938594818\n",
            "Loss:  0.3844951391220093\n",
            "Loss:  0.37507256865501404\n",
            "Time : 1704.6817548274994 secs\n",
            "Epoch: 8\n",
            "Loss:  0.4410943388938904\n",
            "Loss:  0.42451226711273193\n",
            "Loss:  0.3679952323436737\n",
            "Loss:  0.3832191228866577\n",
            "Loss:  0.3924063742160797\n",
            "Loss:  0.36282727122306824\n",
            "Loss:  0.36929622292518616\n",
            "Loss:  0.42314717173576355\n",
            "Loss:  0.32537880539894104\n",
            "Loss:  0.35537657141685486\n",
            "Loss:  0.36263546347618103\n",
            "Loss:  0.37532535195350647\n",
            "Loss:  0.3823462724685669\n",
            "Loss:  0.3705644905567169\n",
            "Time : 1703.3776986598969 secs\n",
            "Epoch: 9\n",
            "Loss:  0.4503784775733948\n",
            "Loss:  0.4137464165687561\n",
            "Loss:  0.3647514283657074\n",
            "Loss:  0.37564730644226074\n",
            "Loss:  0.38929587602615356\n",
            "Loss:  0.35783928632736206\n",
            "Loss:  0.36327195167541504\n",
            "Loss:  0.39872634410858154\n",
            "Loss:  0.30454838275909424\n",
            "Loss:  0.36258789896965027\n",
            "Loss:  0.355938583612442\n",
            "Loss:  0.3870515823364258\n",
            "Loss:  0.38484179973602295\n",
            "Loss:  0.37373679876327515\n",
            "Time : 1704.8123941421509 secs\n",
            "Epoch: 10\n",
            "Loss:  0.44071370363235474\n",
            "Loss:  0.40672409534454346\n",
            "Loss:  0.3643358647823334\n",
            "Loss:  0.36742669343948364\n",
            "Loss:  0.3928202986717224\n",
            "Loss:  0.3519136905670166\n",
            "Loss:  0.36146700382232666\n",
            "Loss:  0.40404972434043884\n",
            "Loss:  0.32197657227516174\n",
            "Loss:  0.356254905462265\n",
            "Loss:  0.3603202998638153\n",
            "Loss:  0.38220807909965515\n",
            "Loss:  0.3719066083431244\n",
            "Loss:  0.3708702325820923\n",
            "Time : 1704.1807639598846 secs\n",
            "Epoch: 11\n",
            "Loss:  0.4349156320095062\n",
            "Loss:  0.3994191586971283\n",
            "Loss:  0.3545098900794983\n",
            "Loss:  0.3683285713195801\n",
            "Loss:  0.38391053676605225\n",
            "Loss:  0.35326245427131653\n",
            "Loss:  0.3554510474205017\n",
            "Loss:  0.40154972672462463\n",
            "Loss:  0.3102772533893585\n",
            "Loss:  0.3591584861278534\n",
            "Loss:  0.3508482575416565\n",
            "Loss:  0.3810495436191559\n",
            "Loss:  0.3696589767932892\n",
            "Loss:  0.35469850897789\n",
            "Time : 1704.786553144455 secs\n",
            "Epoch: 12\n",
            "Loss:  0.4344785809516907\n",
            "Loss:  0.40027472376823425\n",
            "Loss:  0.3492211401462555\n",
            "Loss:  0.3663727641105652\n",
            "Loss:  0.36986956000328064\n",
            "Loss:  0.33864691853523254\n",
            "Loss:  0.3436993360519409\n",
            "Loss:  0.38325178623199463\n",
            "Loss:  0.30932971835136414\n",
            "Loss:  0.3492495119571686\n",
            "Loss:  0.3467991054058075\n",
            "Loss:  0.36538997292518616\n",
            "Loss:  0.37339192628860474\n",
            "Loss:  0.36816439032554626\n",
            "Time : 1702.9814355373383 secs\n",
            "Epoch: 13\n",
            "Loss:  0.4370497465133667\n",
            "Loss:  0.3949206471443176\n",
            "Loss:  0.3470224440097809\n",
            "Loss:  0.3598458170890808\n",
            "Loss:  0.3736691176891327\n",
            "Loss:  0.3451909124851227\n",
            "Loss:  0.3521067500114441\n",
            "Loss:  0.38435545563697815\n",
            "Loss:  0.31532901525497437\n",
            "Loss:  0.3429808020591736\n",
            "Loss:  0.3325261175632477\n",
            "Loss:  0.3527631163597107\n",
            "Loss:  0.3636256754398346\n",
            "Loss:  0.36156266927719116\n",
            "Time : 1705.3293516635895 secs\n",
            "Epoch: 14\n",
            "Loss:  0.417442262172699\n",
            "Loss:  0.3951781690120697\n",
            "Loss:  0.35087940096855164\n",
            "Loss:  0.35939207673072815\n",
            "Loss:  0.3768262267112732\n",
            "Loss:  0.34191590547561646\n",
            "Loss:  0.3389457166194916\n",
            "Loss:  0.3862345218658447\n",
            "Loss:  0.3030627965927124\n",
            "Loss:  0.3476719558238983\n",
            "Loss:  0.3316706717014313\n",
            "Loss:  0.3560170829296112\n",
            "Loss:  0.35829299688339233\n",
            "Loss:  0.3521943688392639\n",
            "Time : 1705.6950252056122 secs\n",
            "Now generating paraphrases on our fine tuned model for the validation dataset and saving it in a dataframe\n",
            "Completed 0\n",
            "Completed 64\n",
            "Output Files generated for review\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def main():\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
        "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    # Log metrics with wandb\n",
        "    wandb.watch(model, log=\"all\")\n",
        "    # Training loop\n",
        "    print('Initiating Fine-Tuning for the model on our dataset')\n",
        "\n",
        "    for epoch in range(config.TRAIN_EPOCHS):\n",
        "        begin=time.time()\n",
        "        train(epoch, tokenizer, model, train_dataloader, optimizer)\n",
        "        end=time.time()\n",
        "        print(f\"Time : {end-begin} secs\")\n",
        "\n",
        "\n",
        "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
        "    # Saving the dataframe as predictions.csv\n",
        "    print('Now generating paraphrases on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
        "    for epoch in range(config.VAL_EPOCHS):\n",
        "        input_texts, predictions, actuals = validate(epoch, tokenizer, model, test_dataloader)\n",
        "        final_df = pd.DataFrame({'Prompt':input_texts, 'Generated Text':predictions,'Actual Text':actuals})\n",
        "        final_df.to_csv('./outputs/google_t5_df/predictions.csv')\n",
        "        print('Output Files generated for review')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference using a single prompt"
      ],
      "metadata": {
        "id": "OKA8JXxcZkeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''import torch\n",
        "\n",
        "text = 'paraphrase: Are Muslim women allowed to pray in the Mosques in India?'\n",
        "# Tokenize the prompt\n",
        "text_tokenized = tokenizer(text,\n",
        "                            max_length=max_input_length,\n",
        "                            padding=\"max_length\",truncation=True,  # Ensure longer texts are truncated to 'max_length'\n",
        "                            #return_tensors='pt'  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "input_ids = torch.tensor(text_tokenized['input_ids']).unsqueeze(0)  # Add batch dimension\n",
        "attention_mask = torch.tensor(text_tokenized['attention_mask']).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    input_ids=input_ids.to(model.device),\n",
        "    attention_mask=attention_mask.to(model.device),\n",
        "    max_length=max_output_length,\n",
        "    num_beams=2,\n",
        "    repetition_penalty=2.5,\n",
        "    length_penalty=1.0,\n",
        "    early_stopping=True\n",
        ")\n",
        "preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "preds'''"
      ],
      "metadata": {
        "id": "V9o4-T5hU344"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "l7oM7l8zi3Ah"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}